{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c228bb",
   "metadata": {},
   "source": [
    "### Instalaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d474de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de Librerías (ejecutar solo una vez si no están instaladas)\n",
    "# !pip install langgraph langchain langchain_aws boto3 python-dotenv anthropic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ddbed",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49f5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage \n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f955e",
   "metadata": {},
   "source": [
    "### Configuración del Cliente de Bedrock y LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f99a47e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente de Bedrock Runtime inicializado exitosamente.\n",
      "LLM (amazon.titan-text-express-v1) inicializado exitosamente con ChatBedrock.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    \n",
    "    bedrock_runtime_client = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        # region_name=region_name \n",
    "    )\n",
    "    print(\"Cliente de Bedrock Runtime inicializado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inicializando el cliente de Bedrock Runtime: {e}\")\n",
    "    print(\"Por favor, verifica tu configuración de credenciales y región de AWS.\")\n",
    "    \n",
    "\n",
    "\n",
    "#MODEL_ID_HAIKU = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "#MODEL_ID_SONNET = \"anthropic.claude-3-sonnet-20240229-v1:0\" \n",
    "MODEL_ID_TITAN_EXPRESS = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "\n",
    "try:\n",
    "    llm = ChatBedrock(\n",
    "        client=bedrock_runtime_client, \n",
    "        model_id=MODEL_ID_TITAN_EXPRESS,\n",
    "        model_kwargs={\n",
    "            \"temperature\": 0.1, \n",
    "            \"max_tokens\": 1024    \n",
    "        }\n",
    "    )\n",
    "    print(f\"LLM ({MODEL_ID_TITAN_EXPRESS}) inicializado exitosamente con ChatBedrock.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inicializando ChatBedrock con {MODEL_ID_TITAN_EXPRESS}: {e}\")\n",
    "    print(\"Asegúrate de que el modelo Titan Text Express está habilitado en tu cuenta de Bedrock para la región configurada, o que los model_kwargs son correctos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0671c",
   "metadata": {},
   "source": [
    "### Definición del Estado del Grafo (AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AgentState(TypedDict):\n",
    "    userInput: str\n",
    "    intent: str\n",
    "    entities: dict\n",
    "    catalogQueryResult: List[dict]\n",
    "    finalResponse: str\n",
    "    callLog: List[str] \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef15ff5",
   "metadata": {},
   "source": [
    "### Definición del Nodo - Interpretar Entrada del Usuario (NLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_user_input(state: AgentState):\n",
    "    \"\"\"\n",
    "    Toma la entrada del usuario y usa el LLM para extraer la intención y las entidades.\n",
    "    Ajustado para forzar una salida JSON más estricta con modelos como Titan.\n",
    "    \"\"\"\n",
    "    print(\"---NODO: Interpretando Entrada del Usuario (con Titan, intento #3)---\")\n",
    "    user_input = state[\"userInput\"]\n",
    "    current_call_log = state.get(\"callLog\", [])\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"Tu única función es analizar la consulta del usuario y DEVOLVER ÚNICAMENTE UN OBJETO JSON VÁLIDO. \"\n",
    "                \"NO INCLUYAS NINGÚN TEXTO EXPLICATIVO, SALUDO, COMENTARIO, O CUALQUIER OTRA COSA FUERA DEL OBJETO JSON. \"\n",
    "                \"El objeto JSON debe tener exactamente dos claves de nivel superior: 'intent' (string) y 'entities' (un diccionario). \"\n",
    "                \"Las intenciones posibles son: 'buscar_producto', 'comparar_productos', 'pedir_recomendacion', 'ver_carrito', 'saludar', 'despedirse', 'otra'. \"\n",
    "                \"Las entidades comunes son: 'nombre_producto', 'marca', 'categoria', 'color', 'talla', 'precio_maximo', 'caracteristicas_adicionales'. \"\n",
    "                \"Si una entidad no se encuentra, no la incluyas en el diccionario 'entities'. \"\n",
    "                \"Si la intención no es clara o no hay entidades, usa 'otra' y un diccionario 'entities' vacío. \"\n",
    "                \"Ejemplo de la ÚNICA salida que debes producir: \"\n",
    "                \"{\\\"intent\\\": \\\"buscar_producto\\\", \\\"entities\\\": {\\\"categoria\\\": \\\"televisor\\\", \\\"marca\\\": \\\"LG\\\"}}\\n\"\n",
    "                \"REPITO: Tu respuesta DEBE SER SOLO EL OBJETO JSON y nada más.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessage(content=f\"Analiza esta consulta: {user_input}\")\n",
    "    ])\n",
    "\n",
    "    response_content = \"\" \n",
    "    try:\n",
    "        formatted_prompt = prompt_template.format_messages(userInput=user_input)\n",
    "        ai_response = llm.invoke(formatted_prompt)\n",
    "\n",
    "        response_content = ai_response.content.strip()\n",
    "        print(f\"Respuesta cruda del LLM para NLU (Titan): {response_content}\")\n",
    "\n",
    "        \n",
    "        json_start_index = response_content.find('{')\n",
    "        json_end_index = response_content.rfind('}')\n",
    "\n",
    "        if json_start_index != -1 and json_end_index != -1 and json_end_index > json_start_index:\n",
    "            potential_json_string = response_content[json_start_index : json_end_index + 1]\n",
    "            print(f\"String JSON potencial extraído: {potential_json_string}\")\n",
    "            try:\n",
    "                parsed_response = json.loads(potential_json_string)\n",
    "            except json.JSONDecodeError as e_inner:\n",
    "                print(f\"Fallo al parsear el string JSON extraído: {e_inner}. Intentando con la respuesta original.\")\n",
    "                parsed_response = json.loads(response_content) \n",
    "        else:\n",
    "            print(\"No se encontraron delimitadores JSON claros ('{' y '}'). Intentando parsear la respuesta original.\")\n",
    "            parsed_response = json.loads(response_content)\n",
    "\n",
    "\n",
    "        intent = parsed_response.get(\"intent\", \"otra\")\n",
    "        entities = parsed_response.get(\"entities\", {})\n",
    "\n",
    "        current_call_log.append(f\"NLU: Input='{user_input}', Intent='{intent}', Entities='{json.dumps(entities)}', LLM_Raw_Output='{response_content[:200]}...'\")\n",
    "        print(f\"Intención extraída: {intent}\")\n",
    "        print(f\"Entidades extraídas: {entities}\")\n",
    "\n",
    "        return {\n",
    "            \"intent\": intent,\n",
    "            \"entities\": entities,\n",
    "            \"callLog\": current_call_log\n",
    "        }\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error FINAL al decodificar la respuesta JSON del LLM (Titan): {e}\")\n",
    "        print(f\"Respuesta del LLM que causó el error (después de intentos de limpieza): {response_content}\")\n",
    "        current_call_log.append(f\"NLU_ERROR: Error decodificando JSON. LLM_Raw_Output='{response_content[:200]}...'\")\n",
    "        return {\n",
    "            \"intent\": \"error_nlu_format\",\n",
    "            \"entities\": {},\n",
    "            \"callLog\": current_call_log\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado durante la NLU (Titan): {e}\")\n",
    "        current_call_log.append(f\"NLU_ERROR: Error inesperado - {str(e)}\")\n",
    "        return {\n",
    "            \"intent\": \"error_nlu_unexpected\",\n",
    "            \"entities\": {},\n",
    "            \"callLog\": current_call_log\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218395bd",
   "metadata": {},
   "source": [
    "### Definición del Nodo - Consultar Catálogo de Productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40473a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os   \n",
    "\n",
    "def load_product_database(db_path=\"../data/products.json\"):\n",
    "    \"\"\"\n",
    "    Carga la base de datos de productos desde un archivo JSON.\n",
    "    Asume que el archivo products.json está en una carpeta 'data'\n",
    "    ubicada un nivel arriba de la carpeta donde se encuentra este notebook.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Para verificar la ruta actual desde donde se ejecuta el notebook \n",
    "    # print(f\"Directorio de trabajo actual: {os.getcwd()}\")\n",
    "    # print(f\"Intentando cargar DB desde: {os.path.abspath(db_path)}\")\n",
    "\n",
    "    try:\n",
    "        with open(db_path, 'r', encoding='utf-8') as f:\n",
    "            database = json.load(f)\n",
    "        print(f\"Base de datos de productos cargada exitosamente desde '{os.path.abspath(db_path)}'\")\n",
    "        return database\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR CRÍTICO: Archivo de base de datos no encontrado en '{os.path.abspath(db_path)}'.\")\n",
    "        print(\"Asegúrate de que la carpeta 'data' exista en la raíz de tu proyecto y contenga 'products.json'.\")\n",
    "        print(f\"Directorio actual: {os.getcwd()}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"ERROR CRÍTICO: Error al decodificar el archivo JSON en '{os.path.abspath(db_path)}'. Verifica el formato del archivo.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR CRÍTICO: Ocurrió un error inesperado al cargar la base de datos: {e}\")\n",
    "        return []\n",
    "\n",
    "def query_product_catalog(state: AgentState):\n",
    "    \"\"\"\n",
    "    Consulta un catálogo de productos (cargado desde un archivo JSON) basado en las entidades extraídas.\n",
    "    \"\"\"\n",
    "    print(\"---NODO: Consultando Catálogo de Productos (desde Archivo JSON)---\")\n",
    "    entities = state.get(\"entities\", {})\n",
    "    intent = state.get(\"intent\", \"\")\n",
    "    current_call_log = state.get(\"callLog\", [])\n",
    "\n",
    "    \n",
    "    product_database = load_product_database() \n",
    "\n",
    "    if not product_database: \n",
    "        current_call_log.append(\"CATALOG_ERROR: La base de datos de productos no se pudo cargar o está vacía.\")\n",
    "        print(\"Error: La base de datos de productos está vacía o no se pudo cargar. Revisa los mensajes anteriores.\")\n",
    "        return {\"catalogQueryResult\": [], \"callLog\": current_call_log}\n",
    "\n",
    "    \n",
    "    if intent not in [\"buscar_producto\", \"pedir_recomendacion\", \"comparar_productos\"]:\n",
    "        print(f\"Intención '{intent}' no requiere consulta de catálogo. Omitiendo.\")\n",
    "        current_call_log.append(f\"CATALOG_SKIP: Intención '{intent}' no requiere consulta.\")\n",
    "        return {\"catalogQueryResult\": [], \"callLog\": current_call_log}\n",
    "\n",
    "    print(f\"Consultando catálogo con entidades: {entities}\")\n",
    "    \n",
    "    results = []\n",
    "    if not entities:\n",
    "        print(\"No se proporcionaron entidades para filtrar. Considera devolver algunos productos populares o ninguno.\")\n",
    "        # results = product_database[:3] \n",
    "        results = [] \n",
    "    else:\n",
    "        for product in product_database:\n",
    "            match = True\n",
    "            # Comprobar categoría\n",
    "            entity_categoria = entities.get(\"categoria\", \"\").lower()\n",
    "            product_categoria = product.get(\"categoria\", \"\").lower()\n",
    "            if entity_categoria and entity_categoria not in product_categoria:\n",
    "                match = False\n",
    "            \n",
    "            # Comprobar marca\n",
    "            entity_marca = entities.get(\"marca\", \"\").lower()\n",
    "            product_marca = product.get(\"marca\", \"\").lower()\n",
    "            if entity_marca and entity_marca not in product_marca:\n",
    "                match = False\n",
    "            \n",
    "            # Comprobar nombre_producto \n",
    "            entity_nombre = entities.get(\"nombre_producto\", \"\").lower()\n",
    "            product_nombre = product.get(\"nombre\", \"\").lower()\n",
    "            if entity_nombre and entity_nombre not in product_nombre: \n",
    "                match = False\n",
    "            \n",
    "            # Comprobar color \n",
    "            entity_color = entities.get(\"color\", \"\").lower()\n",
    "            product_colores = [str(c).lower() for c in product.get(\"colores\", [])] # Asegurar que sean strings\n",
    "            if entity_color and product_colores and entity_color not in product_colores:\n",
    "                match = False\n",
    "            \n",
    "            # Comprobar talla \n",
    "            entity_talla = str(entities.get(\"talla\", \"\")) \n",
    "            product_tallas = [str(t) for t in product.get(\"tallas_disponibles\", [])] \n",
    "            if entity_talla and product_tallas and entity_talla not in product_tallas:\n",
    "                match = False\n",
    "            \n",
    "            if match:\n",
    "                results.append(product)\n",
    "\n",
    "    if not results:\n",
    "        print(\"No se encontraron productos que coincidan con las entidades.\")\n",
    "        current_call_log.append(f\"CATALOG_QUERY: Entities='{json.dumps(entities)}', Result='No products found'\")\n",
    "    else:\n",
    "        print(f\"Productos encontrados: {len(results)}\")\n",
    "        summary_results = [{\"id\": p.get(\"id\"), \"nombre\": p.get(\"nombre\")} for p in results[:3]]\n",
    "        current_call_log.append(f\"CATALOG_QUERY: Entities='{json.dumps(entities)}', Found='{len(results)} items', ExampleResults='{json.dumps(summary_results)}'\")\n",
    "\n",
    "    return {\n",
    "        \"catalogQueryResult\": results,\n",
    "        \"callLog\": current_call_log\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859a9c8",
   "metadata": {},
   "source": [
    "### Definición del Nodo - Generar Respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(state: AgentState):\n",
    "    \"\"\"\n",
    "    Genera una respuesta en lenguaje natural basada en los resultados de la consulta al catálogo\n",
    "    y la intención/entidades del usuario.\n",
    "    \"\"\"\n",
    "    print(\"---NODO: Generando Respuesta---\")\n",
    "    user_input = state.get(\"userInput\", \"\")\n",
    "    intent = state.get(\"intent\", \"\")\n",
    "    entities = state.get(\"entities\", {})\n",
    "    catalog_results = state.get(\"catalogQueryResult\", [])\n",
    "    current_call_log = state.get(\"callLog\", [])\n",
    "    \n",
    "    context_for_llm = f\"La consulta original del usuario fue: '{user_input}'.\\n\"\n",
    "    context_for_llm += f\"La intención identificada fue: '{intent}'.\\n\"\n",
    "    if entities:\n",
    "        context_for_llm += f\"Las entidades extraídas fueron: {json.dumps(entities)}.\\n\"\n",
    "\n",
    "    if intent == \"error_nlu\":\n",
    "        final_response_text = \"Lo siento, tuve problemas para entender tu solicitud. ¿Podrías intentarlo de nuevo de otra manera?\"\n",
    "        current_call_log.append(f\"RESPONSE_GEN: Intent='{intent}', Generated_Response='{final_response_text}'\")\n",
    "        return {\"finalResponse\": final_response_text, \"callLog\": current_call_log}\n",
    "\n",
    "    if intent in [\"saludar\", \"despedirse\"] and not catalog_results: \n",
    "        if intent == \"saludar\":\n",
    "            final_response_text = \"¡Hola! Soy tu asistente de compras. ¿En qué puedo ayudarte hoy?\"\n",
    "        elif intent == \"despedirse\":\n",
    "            final_response_text = \"¡Hasta luego! Que tengas un buen día.\"\n",
    "        else: # Por si acaso\n",
    "            final_response_text = \"Entendido.\"\n",
    "        current_call_log.append(f\"RESPONSE_GEN: Intent='{intent}', Generated_Response='{final_response_text}'\")\n",
    "        return {\"finalResponse\": final_response_text, \"callLog\": current_call_log}\n",
    "\n",
    "\n",
    "    if not catalog_results:\n",
    "        if intent in [\"buscar_producto\", \"pedir_recomendacion\", \"comparar_productos\"]:\n",
    "            context_for_llm += \"No se encontraron productos que coincidan exactamente con tu búsqueda en el catálogo.\\n\"\n",
    "            system_message_content = (\n",
    "                \"Eres un asistente de compras amigable y servicial. \"\n",
    "                \"El usuario realizó una búsqueda pero no se encontraron productos. \"\n",
    "                \"Informa al usuario de esto de manera amigable y quizás sugiere que intente una búsqueda diferente o más general. \"\n",
    "                \"No inventes productos. Sé breve y directo.\"\n",
    "            )\n",
    "        else:\n",
    "            context_for_llm += \"No se requirió ni se obtuvo información del catálogo para esta consulta.\\n\"\n",
    "            system_message_content = (\n",
    "                \"Eres un asistente de compras amigable y servicial. \"\n",
    "                \"Responde al usuario de forma concisa basándote en la intención y el contexto proporcionado. \"\n",
    "                \"Si la intención no está clara, pide una aclaración.\"\n",
    "            )\n",
    "    else:\n",
    "        context_for_llm += \"Se encontraron los siguientes productos en el catálogo que podrían ser relevantes:\\n\"\n",
    "        for i, product in enumerate(catalog_results[:3]): \n",
    "            context_for_llm += f\"  Producto {i+1}: {product.get('nombre', 'Nombre no disponible')} (Marca: {product.get('marca', 'N/A')}, Precio: ${product.get('precio', 'N/A')})\\n\"\n",
    "            if product.get('descripcion'):\n",
    "                 context_for_llm += f\"    Descripción: {product.get('descripcion')}\\n\"\n",
    "        if len(catalog_results) > 3:\n",
    "            context_for_llm += f\"  ... y {len(catalog_results) - 3} productos más.\\n\"\n",
    "        \n",
    "        system_message_content = (\n",
    "            \"Eres un asistente de compras amigable y servicial. \"\n",
    "            \"Basándote en la consulta del usuario y los productos encontrados en el catálogo (proporcionados en el contexto), \"\n",
    "            \"genera una respuesta útil y conversacional. Resume la información si es necesario. \"\n",
    "            \"Si hay varios productos, puedes mencionar algunos y preguntar si el usuario desea más detalles sobre alguno en particular. \"\n",
    "            \"No inventes productos ni características que no estén en la lista.\"\n",
    "        )\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_message_content),\n",
    "        HumanMessage(content=context_for_llm + \"\\nPor favor, genera una respuesta adecuada para el usuario.\")\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        formatted_prompt = prompt_template.format_messages() \n",
    "        ai_response = llm.invoke(formatted_prompt)\n",
    "        final_response_text = ai_response.content.strip()\n",
    "\n",
    "        print(f\"Respuesta generada por el LLM: {final_response_text}\")\n",
    "        current_call_log.append(f\"RESPONSE_GEN: Intent='{intent}', Found_Items='{len(catalog_results)}', Generated_Response='{final_response_text[:200]}...'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la generación de respuesta con el LLM: {e}\")\n",
    "        current_call_log.append(f\"RESPONSE_GEN_ERROR: Error - {str(e)}\")\n",
    "        final_response_text = \"Lo siento, estoy teniendo problemas para generar una respuesta en este momento. Intenta de nuevo más tarde.\"\n",
    "\n",
    "    return {\n",
    "        \"finalResponse\": final_response_text,\n",
    "        \"callLog\": current_call_log\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cfbd99",
   "metadata": {},
   "source": [
    "### Ensamblaje del Grafo LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94b4167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo LangGraph compilado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"nlu_parser\", interpret_user_input)\n",
    "workflow.add_node(\"catalog_tool\", query_product_catalog)\n",
    "workflow.add_node(\"response_generator\", generate_response)\n",
    "\n",
    "workflow.set_entry_point(\"nlu_parser\")\n",
    "\n",
    "workflow.add_edge(\"nlu_parser\", \"catalog_tool\")\n",
    "\n",
    "workflow.add_edge(\"catalog_tool\", \"response_generator\")\n",
    "\n",
    "workflow.add_edge(\"response_generator\", END)\n",
    "\n",
    "\n",
    "try:\n",
    "    app = workflow.compile()\n",
    "    print(\"Grafo LangGraph compilado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al compilar el grafo LangGraph: {e}\")\n",
    "    app = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded23661",
   "metadata": {},
   "source": [
    "### Ejecutar el Agente con una Entrada de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ba93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EJECUTANDO EL AGENTE ---\n",
      "Entrada del Usuario: \"Hola, estoy buscando un televisor SuperVision de 55 pulgadas, ¿tienes alguno?\"\n",
      "---NODO: Interpretando Entrada del Usuario (con Titan, intento #3)---\n",
      "Respuesta cruda del LLM para NLU (Titan): {\"intent\": \"buscar_producto\", \"entities\": {\"categoria\": \"televisor\", \"marca\": \"LG\"}}\n",
      "String JSON potencial extraído: {\"intent\": \"buscar_producto\", \"entities\": {\"categoria\": \"televisor\", \"marca\": \"LG\"}}\n",
      "Intención extraída: buscar_producto\n",
      "Entidades extraídas: {'categoria': 'televisor', 'marca': 'LG'}\n",
      "---NODO: Consultando Catálogo de Productos (desde Archivo JSON)---\n",
      "Base de datos de productos cargada exitosamente desde 'c:\\Users\\Sebastian Diaz G\\OneDrive\\asistente-compras-inteligente\\asistente-compras-inteligente\\data\\products.json'\n",
      "Consultando catálogo con entidades: {'categoria': 'televisor', 'marca': 'LG'}\n",
      "No se encontraron productos que coincidan con las entidades.\n",
      "---NODO: Generando Respuesta---\n",
      "Respuesta generada por el LLM: Hola, lamentablemente no tenemos ningún televisor SuperVision de 55 pulgadas en el catálogo. Sin embargo, tenemos otros modelos de televisores LG que podrían interesarte. ¿Te gustaría que te sugiriera algunos?\n",
      "\n",
      "--- RESULTADO FINAL DEL AGENTE ---\n",
      "Respuesta Final para el Usuario: Hola, lamentablemente no tenemos ningún televisor SuperVision de 55 pulgadas en el catálogo. Sin embargo, tenemos otros modelos de televisores LG que podrían interesarte. ¿Te gustaría que te sugiriera algunos?\n",
      "\n",
      "--- LOG DE LLAMADAS (Rendimiento/Supervisión) ---\n",
      "NLU: Input='Hola, estoy buscando un televisor SuperVision de 55 pulgadas, ¿tienes alguno?', Intent='buscar_producto', Entities='{\"categoria\": \"televisor\", \"marca\": \"LG\"}', LLM_Raw_Output='{\"intent\": \"buscar_producto\", \"entities\": {\"categoria\": \"televisor\", \"marca\": \"LG\"}}...'\n",
      "CATALOG_QUERY: Entities='{\"categoria\": \"televisor\", \"marca\": \"LG\"}', Result='No products found'\n",
      "RESPONSE_GEN: Intent='buscar_producto', Found_Items='0', Generated_Response='Hola, lamentablemente no tenemos ningún televisor SuperVision de 55 pulgadas en el catálogo. Sin embargo, tenemos otros modelos de televisores LG que podrían interesarte. ¿Te gustaría que te sugiriera...'\n"
     ]
    }
   ],
   "source": [
    "if app:\n",
    "    print(\"\\n--- EJECUTANDO EL AGENTE ---\")\n",
    "    \n",
    "    # Definir la entrada del usuario\n",
    "    user_query = \"Hola, estoy buscando un televisor SuperVision de 55 pulgadas, tienes alguno?\"\n",
    "    # user_query = \"Tienes zapatillas RunnerFlex rojas talla 42?\"\n",
    "    # user_query = \"Qué tal?\"\n",
    "    # user_query = \"Adiós\"\n",
    "    # user_query = \"Busco un taladro percutor\" \n",
    "\n",
    "    initial_state_input = {\"userInput\": user_query, \"callLog\": []} \n",
    "\n",
    "    print(f\"Entrada del Usuario: \\\"{user_query}\\\"\")\n",
    "    \n",
    "    # Invocar el agente con la entrada.\n",
    "    \n",
    "    try:\n",
    "        final_state = app.invoke(initial_state_input)\n",
    "\n",
    "        # Mostrar la respuesta final y el log de llamadas\n",
    "        print(\"\\n--- RESULTADO FINAL DEL AGENTE ---\")\n",
    "        print(f\"Respuesta Final para el Usuario: {final_state.get('finalResponse', 'No se generó respuesta final.')}\")\n",
    "        \n",
    "        print(\"\\n--- LOG DE LLAMADAS (Rendimiento/Supervisión) ---\")\n",
    "        if final_state.get('callLog'):\n",
    "            for log_entry in final_state['callLog']:\n",
    "                print(log_entry)\n",
    "        else:\n",
    "            print(\"El log de llamadas está vacío.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la ejecución del agente: {e}\")\n",
    "        print(\"Detalles del estado en el momento del error (si está disponible en la excepción):\")\n",
    "        \n",
    "       \n",
    "        if hasattr(e, 'state'):\n",
    "             print(json.dumps(e.state, indent=2, ensure_ascii=False))\n",
    "\n",
    "else:\n",
    "    print(\"El agente no se pudo compilar. No se puede ejecutar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac650b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
