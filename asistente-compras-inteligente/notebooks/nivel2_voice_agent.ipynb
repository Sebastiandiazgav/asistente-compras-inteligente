{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc0dfa7",
   "metadata": {},
   "source": [
    "### Importaciones y Configuración de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c4c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes de S3, Transcribe y Bedrock Runtime inicializados para la región: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from typing import TypedDict, List\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\")\n",
    "if not aws_region:\n",
    "    print(\"Advertencia: AWS_DEFAULT_REGION no está configurada. Usando la región por defecto del SDK.\")\n",
    "\n",
    "s3_client = None\n",
    "transcribe_client = None\n",
    "bedrock_runtime_client = None\n",
    "\n",
    "try:\n",
    "    s3_client = boto3.client('s3', region_name=aws_region)\n",
    "    transcribe_client = boto3.client('transcribe', region_name=aws_region)\n",
    "    bedrock_runtime_client = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=aws_region\n",
    "    )\n",
    "    print(f\"Clientes de S3, Transcribe y Bedrock Runtime inicializados para la región: {aws_region or (bedrock_runtime_client.meta.region_name if bedrock_runtime_client else 'No disponible')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inicializando clientes de AWS: {e}\")\n",
    "  \n",
    "# Líneas de verificación \n",
    "#if 'bedrock_runtime_client' in globals() and bedrock_runtime_client is not None:\n",
    "#    print(f\"Verificando bedrock_runtime_client después de la Celda 1: {type(bedrock_runtime_client)}\")\n",
    "#else:\n",
    "#    print(\"bedrock_runtime_client NO está definido o es None después de la inicialización en Celda 1.\")\n",
    "#\n",
    "#if 's3_client' in globals() and s3_client is not None:\n",
    "#    print(f\"Verificando s3_client después de la Celda 1: {type(s3_client)}\")\n",
    "#else:\n",
    "#    print(\"s3_client NO está definido o es None después de la inicialización en Celda 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c889d4",
   "metadata": {},
   "source": [
    "### Definición de la Función para Transcribir Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d64003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_file(audio_file_path: str, bucket_name: str, job_name_prefix: str = \"Nivel2-VoiceAgent-Transcription-\"):\n",
    "    \"\"\"\n",
    "    Sube un archivo de audio a S3, inicia un trabajo de transcripción en Amazon Transcribe,\n",
    "    espera a que se complete y devuelve el texto transcrito.\n",
    "\n",
    "    Args:\n",
    "        audio_file_path (str): Ruta local al archivo de audio.\n",
    "        bucket_name (str): Nombre del bucket de S3 donde se subirá el audio.\n",
    "        job_name_prefix (str): Prefijo para el nombre del trabajo de transcripción.\n",
    "\n",
    "    Returns:\n",
    "        str: El texto transcrito, o None si ocurre un error.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(audio_file_path):\n",
    "        print(f\"Error: El archivo de audio no se encuentra en '{audio_file_path}'\")\n",
    "        return None\n",
    "\n",
    "    file_name = os.path.basename(audio_file_path)\n",
    "    unique_id = str(uuid.uuid4())\n",
    "    s3_object_key = f\"transcribe-input/{unique_id}-{file_name}\"\n",
    "    transcription_job_name = f\"{job_name_prefix}{unique_id}\"\n",
    "\n",
    "    try:\n",
    "        print(f\"Subiendo '{audio_file_path}' a S3 bucket '{bucket_name}' como '{s3_object_key}'...\")\n",
    "        s3_client.upload_file(audio_file_path, bucket_name, s3_object_key)\n",
    "        media_file_uri = f\"s3://{bucket_name}/{s3_object_key}\"\n",
    "        print(f\"Archivo subido a: {media_file_uri}\")\n",
    "\n",
    "        file_format = file_name.split('.')[-1].lower()\n",
    "        if file_format not in ['mp3', 'mp4', 'wav', 'flac', 'ogg', 'amr', 'webm']:\n",
    "            print(f\"Error: Formato de archivo '{file_format}' no soportado directamente por Transcribe. Por favor usa mp3, mp4, wav, flac, ogg, amr, webm.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Iniciando trabajo de transcripción '{transcription_job_name}'...\")\n",
    "        transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName=transcription_job_name,\n",
    "            Media={'MediaFileUri': media_file_uri},\n",
    "            MediaFormat=file_format,\n",
    "            LanguageCode='es-ES'\n",
    "            \n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            status = transcribe_client.get_transcription_job(TranscriptionJobName=transcription_job_name)\n",
    "            job_status = status['TranscriptionJob']['TranscriptionJobStatus']\n",
    "            if job_status in ['COMPLETED', 'FAILED']:\n",
    "                print(f\"Estado del trabajo de transcripción: {job_status}\")\n",
    "                break\n",
    "            print(f\"Procesando transcripción (estado actual: {job_status})... Esperando 10 segundos.\")\n",
    "            time.sleep(10)\n",
    "\n",
    "        if job_status == 'FAILED':\n",
    "            print(f\"Error: El trabajo de transcripción falló. Razón: {status['TranscriptionJob'].get('FailureReason')}\")\n",
    "            return None\n",
    "\n",
    "        transcript_file_uri = status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "        print(f\"Archivo de transcripción disponible en: {transcript_file_uri}\")\n",
    "\n",
    "        response = requests.get(transcript_file_uri)\n",
    "        response.raise_for_status() \n",
    "        transcript_json = response.json()\n",
    "        \n",
    "        transcript_text = transcript_json['results']['transcripts'][0]['transcript']\n",
    "        print(f\"Texto Transcrito: {transcript_text}\")\n",
    "        \n",
    "        return transcript_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error durante el proceso de transcripción: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        try:\n",
    "            print(f\"Limpiando: Eliminando objeto '{s3_object_key}' de S3 bucket '{bucket_name}'...\")\n",
    "            s3_client.delete_object(Bucket=bucket_name, Key=s3_object_key)\n",
    "            print(\"Objeto S3 eliminado.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al eliminar objeto de S3: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b71cc",
   "metadata": {},
   "source": [
    "### Definir Variables para la Transcripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d73021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración actual:\n",
      "  S3_BUCKET_NAME = 'chatvoice01'\n",
      "  LOCAL_AUDIO_FILE_PATH = '../data/audio1.mp3'\n",
      "  Bucket S3 a usar: chatvoice01 (Parece configurado).\n",
      "  Archivo de audio local encontrado en: c:\\Users\\Sebastian Diaz G\\OneDrive\\asistente-compras-inteligente\\asistente-compras-inteligente\\data\\audio1.mp3\n",
      "\n",
      "Configuración de variables parece correcta para continuar.\n"
     ]
    }
   ],
   "source": [
    "S3_BUCKET_NAME = \"chatvoice01\" \n",
    "LOCAL_AUDIO_FILE_PATH = \"../data/audio1.mp3\" \n",
    "\n",
    "\n",
    "bucket_configured_correctly = False \n",
    "audio_file_exists = False \n",
    "print(f\"Configuración actual:\")\n",
    "print(f\"  S3_BUCKET_NAME = '{S3_BUCKET_NAME}'\")\n",
    "print(f\"  LOCAL_AUDIO_FILE_PATH = '{LOCAL_AUDIO_FILE_PATH}'\")\n",
    "\n",
    "\n",
    "placeholder_bucket_name = \"tu-nombre-de-bucket-s3-aqui\"\n",
    "if not S3_BUCKET_NAME or S3_BUCKET_NAME == placeholder_bucket_name:\n",
    "    print(\"\\nERROR DE CONFIGURACIÓN:\")\n",
    "    print(f\"  POR FAVOR, EDITA LA VARIABLE 'S3_BUCKET_NAME' Y DEFINE EL NOMBRE DE TU BUCKET S3.\")\n",
    "    print(f\"  (Valor actual: '{S3_BUCKET_NAME}', Placeholder que se debe cambiar: '{placeholder_bucket_name}')\")\n",
    "else:\n",
    "    print(f\"  Bucket S3 a usar: {S3_BUCKET_NAME} (Parece configurado).\")\n",
    "    bucket_configured_correctly = True\n",
    "\n",
    "\n",
    "absolute_audio_path = os.path.abspath(LOCAL_AUDIO_FILE_PATH)\n",
    "\n",
    "if os.path.exists(absolute_audio_path):\n",
    "    print(f\"  Archivo de audio local encontrado en: {absolute_audio_path}\")\n",
    "    audio_file_exists = True\n",
    "else:\n",
    "    print(\"\\nERROR DE CONFIGURACIÓN:\")\n",
    "    print(f\"  Archivo de audio NO encontrado en la ruta resuelta: '{absolute_audio_path}'\")\n",
    "    print(f\"  (Basado en LOCAL_AUDIO_FILE_PATH: '{LOCAL_AUDIO_FILE_PATH}' y directorio actual: '{os.getcwd()}')\")\n",
    "    print(f\"  POR FAVOR, ASEGÚRATE DE QUE TU ARCHIVO DE AUDIO EXISTA EN ESA RUTA O AJUSTA 'LOCAL_AUDIO_FILE_PATH'.\")\n",
    "\n",
    "if bucket_configured_correctly and audio_file_exists:\n",
    "    print(\"\\nConfiguración de variables parece correcta para continuar.\")\n",
    "else:\n",
    "    print(\"\\nREVISA LOS ERRORES DE CONFIGURACIÓN ANTERIORES ANTES DE CONTINUAR.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a3e30",
   "metadata": {},
   "source": [
    "### Llamar a la función de transcripción y obtener el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe7489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Proceso de Transcripción del Audio ---\n",
      "Intentando transcribir el archivo: c:\\Users\\Sebastian Diaz G\\OneDrive\\asistente-compras-inteligente\\asistente-compras-inteligente\\data\\audio1.mp3\n",
      "Usando el bucket S3: chatvoice01\n",
      "Subiendo '../data/audio1.mp3' a S3 bucket 'chatvoice01' como 'transcribe-input/727bd084-6422-425b-9c81-9149464c1780-audio1.mp3'...\n",
      "Archivo subido a: s3://chatvoice01/transcribe-input/727bd084-6422-425b-9c81-9149464c1780-audio1.mp3\n",
      "Iniciando trabajo de transcripción 'Nivel2-VoiceAgent-Transcription-727bd084-6422-425b-9c81-9149464c1780'...\n",
      "Procesando transcripción (estado actual: IN_PROGRESS)... Esperando 10 segundos.\n",
      "Estado del trabajo de transcripción: COMPLETED\n",
      "Archivo de transcripción disponible en: https://s3.us-east-1.amazonaws.com/aws-transcribe-us-east-1-prod/449814909790/Nivel2-VoiceAgent-Transcription-727bd084-6422-425b-9c81-9149464c1780/22314b1c-ebe9-429e-a56e-fae773d7d104/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAytSbYE1efCx1BMTQehFBVeAQjtwyDuY8rLq87ZrRy0AiAzxu9v%2FPkvUvJjqtVWlhifTZYHTzCnBn1OYNhKaNoVyiq7BQiu%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDI3NjY1NjQzMzE1MyIMHg%2Fs%2FbITNFWZLgaUKo8FXrde1yWIbAI9olhLI84QJZ5a1cmbc55qDMk5LHZOLYM4Nq%2FWqpqb%2Fz7hwGdToPYCS31soconjIiAW0n2tkyojeVLx%2BigdDqOUndLoebniMOiZrrBej%2F5lGRmDGSfMBjzZ3t0nX2YqEQfKJYFD8msBsVK4yJGvGkZ7syRW%2BVHaOIwHWgpdIiZ%2FAsY0Sx0nxzYpntH1TLtq%2F1lnTejTanVfvfINuHKTeXdh50sxSJOQXDPu11CM1%2BTnObM%2FZJ85yNGus85tA5Di48UrQvPpZFHEw0wlvzMZEs%2BAXct1UnMJLiP0cuJ1BSzu2Ndydl4WoYD9L6pG8IOE7vGvxh0H5fFYJhecbwbC9R63FE7L8bvU4WudnIdpKmqxqgX4Z%2BRQasDzypx5lL%2BlMY9ptZZmrpjn44TIwchCBB4fi%2FfzLzGR75o4dmJljQ6evYTiBEVcWv9Jg%2BKVbKfrPbqBTft%2FBVctckwcyCqFdGs%2FISlwb%2B63I61m89ph%2BudReeKoWOoBSYo7v6pC%2BduO0dh%2B2ygN8bQQU7vgPt%2BAwxh5Iy1vR0%2FFpeel65Xoz2vmbBVHifxSD8JjLpUt2DEUWeE0MHf8E%2BjcpTqep5WzTXoUWgMI0VLVUB0w4ga9xOxtj90Rte4SZrat82IbxBeLDpjtDpO%2BAwpVlvu3AKVf2i9152KjeMd8VkqWMIAL%2F69zSTC%2B3BALyrzYGKCFE%2B0UakIfayoyiYMEARPFdK%2F%2F0UoX6xxCpWBirkkR8omK5BqfYc9GuDuEVg%2FuF3L3fvcx5Qw8N5hfFSzj%2FpTwIwDUar2RpV5TEv%2FU8BubXCH3axV4Pw%2BIYGLYqu%2BNWJoVTPegfjitOR5IyfaqYqhwMXe5n1xaiwN4KQTxTDT2rPBBjqyAYToLB61NjlWyHAJ77I27u%2FwHFxyhd5ORhIlsZWOnB2SiThv4zkU5jj2mSIWo53i90%2BpgRGKN56bkBh3y5hox29AcXVeAHtwnHPNTY9Be1kA876CxeFAbh%2FgsSCkKLoD4X6nxtbKs5Bhy4AMpVkoVUVyaEi01SY5cwuzV5MbxGGkmbo1yI%2F1Lx4%2BXXC6NVnrB7OUTWjU8O4p78x2EitzJyOzHEIwaD1yoeKSJjVDGU%2B%2BNxw%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250520T221232Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIAUA2QCFAA2MNTEDOE%2F20250520%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=612257f52b8dc516f4a3800c042740e9e34e5a8ed5e6e41c0b29c6843fec907e\n",
      "Texto Transcrito: buscó un televisor supervisión de 55 pulgadas.\n",
      "Limpiando: Eliminando objeto 'transcribe-input/727bd084-6422-425b-9c81-9149464c1780-audio1.mp3' de S3 bucket 'chatvoice01'...\n",
      "Objeto S3 eliminado.\n",
      "\n",
      "--- Transcripción Exitosa ---\n",
      "Texto Obtenido: \"buscó un televisor supervisión de 55 pulgadas.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando Proceso de Transcripción del Audio ---\")\n",
    "\n",
    "transcribed_text = None\n",
    "\n",
    "if S3_BUCKET_NAME and S3_BUCKET_NAME != \"tu-nombre-de-bucket-s3-aqui\" and \\\n",
    "   LOCAL_AUDIO_FILE_PATH and os.path.exists(os.path.abspath(LOCAL_AUDIO_FILE_PATH)):\n",
    "    \n",
    "    print(f\"Intentando transcribir el archivo: {os.path.abspath(LOCAL_AUDIO_FILE_PATH)}\")\n",
    "    print(f\"Usando el bucket S3: {S3_BUCKET_NAME}\")\n",
    "    \n",
    "\n",
    "    transcribed_text = transcribe_audio_file(\n",
    "        audio_file_path=LOCAL_AUDIO_FILE_PATH,\n",
    "        bucket_name=S3_BUCKET_NAME\n",
    "    )\n",
    "\n",
    "    if transcribed_text:\n",
    "        print(\"\\n--- Transcripción Exitosa ---\")\n",
    "        print(f\"Texto Obtenido: \\\"{transcribed_text}\\\"\")\n",
    "    else:\n",
    "        print(\"\\n--- Fallo en la Transcripción ---\")\n",
    "        print(\"No se pudo obtener el texto transcrito. Revisa los mensajes de error anteriores de la función 'transcribe_audio_file'.\")\n",
    "else:\n",
    "    print(\"Error: No se puede proceder con la transcripción.\")\n",
    "    if not S3_BUCKET_NAME or S3_BUCKET_NAME == \"tu-nombre-de-bucket-s3-aqui\":\n",
    "        print(\"  - El nombre del bucket S3 (S3_BUCKET_NAME) no está configurado correctamente.\")\n",
    "    if not LOCAL_AUDIO_FILE_PATH or not os.path.exists(os.path.abspath(LOCAL_AUDIO_FILE_PATH)):\n",
    "        print(\"  - La ruta al archivo de audio (LOCAL_AUDIO_FILE_PATH) no es válida o el archivo no existe.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4bf0c2",
   "metadata": {},
   "source": [
    "### Configuración del LLM para el Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc9bcf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dentro del TRY para inicializar llm ---\n",
      "  Dentro del TRY, tipo de local_brc_for_chatbedrock (asignado desde global): <class 'botocore.client.BedrockRuntime'>\n",
      "  Dentro del TRY, objeto local_brc_for_chatbedrock: <botocore.client.BedrockRuntime object at 0x0000019E171F5310>\n",
      "LLM del Agente (amazon.titan-text-express-v1) inicializado/verificado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID_TITAN_EXPRESS = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "is_brc_defined_globally = False\n",
    "global_brc_type = None\n",
    "global_brc_object = None\n",
    "\n",
    "if 'bedrock_runtime_client' in globals():\n",
    "    is_brc_defined_globally = True\n",
    "    global_brc_type = type(bedrock_runtime_client)\n",
    "    global_brc_object = bedrock_runtime_client\n",
    "else:\n",
    "    print(\"ANTES del try para llm, bedrock_runtime_client no está en globals().\")\n",
    "\n",
    "try:\n",
    "    print(\"--- Dentro del TRY para inicializar llm ---\")\n",
    "    if 'bedrock_runtime_client' not in globals():\n",
    "        print(\"ERROR CRÍTICO INESPERADO: bedrock_runtime_client desapareció de globals() al entrar al try.\")\n",
    "        raise NameError(\"bedrock_runtime_client no encontrado en globals() dentro del try\")\n",
    "\n",
    "    local_brc_for_chatbedrock = bedrock_runtime_client\n",
    "    \n",
    "    print(f\"  Dentro del TRY, tipo de local_brc_for_chatbedrock (asignado desde global): {type(local_brc_for_chatbedrock)}\")\n",
    "    print(f\"  Dentro del TRY, objeto local_brc_for_chatbedrock: {local_brc_for_chatbedrock}\")\n",
    "\n",
    "    llm = ChatBedrock(\n",
    "        client=local_brc_for_chatbedrock,\n",
    "        model_id=MODEL_ID_TITAN_EXPRESS,\n",
    "        model_kwargs={\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "    )\n",
    "    print(f\"LLM del Agente ({MODEL_ID_TITAN_EXPRESS}) inicializado/verificado exitosamente.\")\n",
    "\n",
    "except NameError as ne:\n",
    "    print(f\"ERROR (NameError) DENTRO DEL TRY para llm: {ne}\")\n",
    "    print(\"  Esto sugiere que la variable referenciada no estaba definida en el momento del error.\")\n",
    "    print(f\"  Verificación de 'bedrock_runtime_client' en globals() DENTRO del except NameError: {'bedrock_runtime_client' in globals()}\")\n",
    "    if 'bedrock_runtime_client' in globals():\n",
    "        print(f\"    Tipo de bedrock_runtime_client en globals() (en except NameError): {type(bedrock_runtime_client)}\")\n",
    "    llm = None\n",
    "\n",
    "except Exception as e:  # Capturar otras excepciones\n",
    "    print(f\"ERROR (Otro tipo) DENTRO DEL TRY para llm: {type(e).__name__} - {e}\")\n",
    "    print(f\"  Error inicializando ChatBedrock para el agente con {MODEL_ID_TITAN_EXPRESS}.\")\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ed8a0",
   "metadata": {},
   "source": [
    "### Definición del Estado del Grafo (AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b651678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AgentState(TypedDict):\n",
    "    userInput: str\n",
    "    intent: str\n",
    "    entities: dict\n",
    "    catalogQueryResult: List[dict]\n",
    "    finalResponse: str\n",
    "    callLog: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca0a47",
   "metadata": {},
   "source": [
    "### Interpretar Entrada del Usuario (NLU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790520e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_user_input(state: AgentState):\n",
    "    \"\"\"\n",
    "    Toma la entrada del usuario y usa el LLM para extraer la intención y las entidades.\n",
    "    Prompt refinado para mejorar la extracción de marcas.\n",
    "    \"\"\"\n",
    "    print(\"---AGENTE NODO: Interpretando Entrada del Usuario (con Titan)---\")\n",
    "    user_input = state[\"userInput\"]\n",
    "    current_call_log = state.get(\"callLog\", [])\n",
    "\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"tu única función es analizar la consulta del usuario y devolver únicamente un objeto json válido. \"\n",
    "                \"no incluyas ningún texto explicativo, saludo, comentario, o cualquier otra cosa fuera del objeto json. \"\n",
    "                \"El objeto JSON debe tener exactamente dos claves de nivel superior: 'intent' (string) y 'entities' (un diccionario). \"\n",
    "                \"Las intenciones posibles son: 'buscar_producto', 'comparar_productos', 'pedir_recomendacion', 'ver_carrito', 'saludar', 'despedirse', 'otra'. \"\n",
    "                \"Las entidades comunes son: 'nombre_producto', 'marca', 'categoria', 'color', 'talla', 'precio_maximo', 'caracteristicas_adicionales'. \"\n",
    "                \"Para la entidad 'marca', si el usuario menciona un nombre específico junto al tipo de producto (ej. 'televisor SuperVision'), considera ese nombre como la marca, incluso si no es una marca globalmente conocida. Extrae el nombre tal cual lo dice el usuario para la marca. \"\n",
    "                \"Si una entidad no se encuentra, no la incluyas en el diccionario 'entities'. \"\n",
    "                \"Si la intención no es clara o no hay entidades, usa 'otra' y un diccionario 'entities' vacío. \"\n",
    "                \"Ejemplo 1 de la ÚNICA salida que debes producir: \"\n",
    "                \"{\\\"intent\\\": \\\"buscar_producto\\\", \\\"entities\\\": {\\\"categoria\\\": \\\"televisor\\\", \\\"marca\\\": \\\"SuperVision\\\", \\\"tamaño\\\": \\\"55 pulgadas\\\"}}\\n\"\n",
    "                \"Ejemplo 2 de la ÚNICA salida que debes producir (si la marca es común): \"\n",
    "                \"{\\\"intent\\\": \\\"buscar_producto\\\", \\\"entities\\\": {\\\"categoria\\\": \\\"laptop\\\", \\\"marca\\\": \\\"Dell\\\"}}\\n\"\n",
    "                \"REPITO: Tu respuesta DEBE SER SOLO EL OBJETO JSON y nada más.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessage(content=f\"Analiza esta consulta: {user_input}\")\n",
    "    ])\n",
    "\n",
    "    response_content = \"\" \n",
    "    try:\n",
    "        if 'llm' not in globals() or not isinstance(llm, ChatBedrock):\n",
    "            print(\"ERROR CRÍTICO: La variable 'llm' (ChatBedrock) no está definida o no es del tipo correcto.\")\n",
    "            print(\"Asegúrate de haber ejecutado la Celda 5 (Configuración del LLM para el Agente) correctamente.\")\n",
    "            current_call_log.append(f\"AGENTE_NLU_ERROR: LLM no configurado.\")\n",
    "            return {\"intent\": \"error_nlu_setup\", \"entities\": {}, \"callLog\": current_call_log}\n",
    "\n",
    "        formatted_prompt = prompt_template.format_messages(userInput=user_input)\n",
    "        ai_response = llm.invoke(formatted_prompt)\n",
    "        response_content = ai_response.content.strip()\n",
    "        print(f\"Respuesta cruda del LLM para NLU (Agente-Titan, prompt refinado): {response_content}\")\n",
    "\n",
    "        json_start_index = response_content.find('{')\n",
    "        json_end_index = response_content.rfind('}')\n",
    "\n",
    "        if json_start_index != -1 and json_end_index != -1 and json_end_index > json_start_index:\n",
    "            potential_json_string = response_content[json_start_index : json_end_index + 1]\n",
    "            print(f\"String JSON potencial extraído (Agente, prompt refinado): {potential_json_string}\")\n",
    "            try:\n",
    "                parsed_response = json.loads(potential_json_string)\n",
    "            except json.JSONDecodeError: # Si falla el string extraído, intentar con el original\n",
    "                print(f\"Fallo al parsear JSON extraído, intentando con original: '{response_content}'\")\n",
    "                parsed_response = json.loads(response_content)\n",
    "        else:\n",
    "            print(f\"No se encontraron delimitadores JSON claros, intentando con original: '{response_content}'\")\n",
    "            parsed_response = json.loads(response_content)\n",
    "\n",
    "        intent = parsed_response.get(\"intent\", \"otra\")\n",
    "        entities = parsed_response.get(\"entities\", {})\n",
    "\n",
    "        current_call_log.append(f\"AGENTE_NLU: Input='{user_input}', Intent='{intent}', Entities='{json.dumps(entities)}', LLM_Raw_Output='{response_content[:100]}...'\")\n",
    "        print(f\"Intención extraída (Agente, prompt refinado): {intent}\")\n",
    "        print(f\"Entidades extraídas (Agente, prompt refinado): {entities}\")\n",
    "        return {\"intent\": intent, \"entities\": entities, \"callLog\": current_call_log}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error FINAL al decodificar la respuesta JSON del LLM (Agente-Titan, prompt refinado): {e}\")\n",
    "        print(f\"Respuesta del LLM que causó el error: {response_content}\")\n",
    "        current_call_log.append(f\"AGENTE_NLU_ERROR: JSONDecodeError. LLM_Raw_Output='{response_content[:100]}...'\")\n",
    "        return {\"intent\": \"error_nlu_format\", \"entities\": {}, \"callLog\": current_call_log}\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado durante la NLU (Agente-Titan, prompt refinado): {e}\")\n",
    "        current_call_log.append(f\"AGENTE_NLU_ERROR: Exception - {str(e)}\")\n",
    "        return {\"intent\": \"error_nlu_unexpected\", \"entities\": {}, \"callLog\": current_call_log}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f096c9",
   "metadata": {},
   "source": [
    "### Consultar Catálogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "845f320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_product_database(db_path=\"../data/products.json\"):\n",
    "    print(f\"Intentando cargar DB desde: {os.path.abspath(db_path)}\")\n",
    "    try:\n",
    "        with open(db_path, 'r', encoding='utf-8') as f:\n",
    "            database = json.load(f)\n",
    "        print(f\"Base de datos de productos (Agente) cargada desde '{os.path.abspath(db_path)}'\")\n",
    "        return database\n",
    "    except FileNotFoundError:\n",
    "        print(f\"AGENTE_CATALOG_ERROR: Archivo DB no encontrado en '{os.path.abspath(db_path)}'.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"AGENTE_CATALOG_ERROR: Error cargando DB: {e}\")\n",
    "        return []\n",
    "\n",
    "def query_product_catalog(state: AgentState):\n",
    "    print(\"---AGENTE NODO: Consultando Catálogo de Productos---\")\n",
    "    entities = state.get(\"entities\", {})\n",
    "    intent = state.get(\"intent\", \"\")\n",
    "    current_call_log = state.get(\"callLog\", [])\n",
    "    product_database = load_product_database()\n",
    "    if not product_database:\n",
    "        current_call_log.append(\"AGENTE_CATALOG_ERROR: DB no cargada o vacía.\")\n",
    "        print(\"Error: La base de datos de productos (Agente) está vacía o no se pudo cargar.\")\n",
    "        return {\"catalogQueryResult\": [], \"callLog\": current_call_log}\n",
    "    if intent not in [\"buscar_producto\", \"pedir_recomendacion\", \"comparar_productos\"]:\n",
    "        current_call_log.append(f\"AGENTE_CATALOG_SKIP: Intención '{intent}' no requiere consulta.\")\n",
    "        return {\"catalogQueryResult\": [], \"callLog\": current_call_log}\n",
    "    print(f\"Consultando catálogo (Agente) con entidades: {entities}\")\n",
    "    results = []\n",
    "    if not entities:\n",
    "        results = []\n",
    "    else:\n",
    "        for product in product_database:\n",
    "            match = True\n",
    "            entity_categoria = entities.get(\"categoria\", \"\").lower()\n",
    "            product_categoria = product.get(\"categoria\", \"\").lower()\n",
    "            if entity_categoria and entity_categoria not in product_categoria: match = False\n",
    "            entity_marca = entities.get(\"marca\", \"\").lower()\n",
    "            product_marca = product.get(\"marca\", \"\").lower()\n",
    "            if entity_marca and entity_marca not in product_marca: match = False\n",
    "            entity_nombre = entities.get(\"nombre_producto\", \"\").lower()\n",
    "            product_nombre = product.get(\"nombre\", \"\").lower()\n",
    "            if entity_nombre and entity_nombre not in product_nombre: match = False\n",
    "            entity_color = entities.get(\"color\", \"\").lower()\n",
    "            product_colores = [str(c).lower() for c in product.get(\"colores\", [])]\n",
    "            if entity_color and product_colores and entity_color not in product_colores: match = False\n",
    "            entity_talla = str(entities.get(\"talla\", \"\"))\n",
    "            product_tallas = [str(t) for t in product.get(\"tallas_disponibles\", [])]\n",
    "            if entity_talla and product_tallas and entity_talla not in product_tallas: match = False\n",
    "            if match: results.append(product)\n",
    "    if not results:\n",
    "        current_call_log.append(f\"AGENTE_CATALOG_QUERY: Entities='{json.dumps(entities)}', Result='No products found'\")\n",
    "    else:\n",
    "        summary_results = [{\"id\": p.get(\"id\"), \"nombre\": p.get(\"nombre\")} for p in results[:3]]\n",
    "        current_call_log.append(f\"AGENTE_CATALOG_QUERY: Entities='{json.dumps(entities)}', Found='{len(results)} items', ExampleResults='{json.dumps(summary_results)}'\")\n",
    "    return {\"catalogQueryResult\": results, \"callLog\": current_call_log}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837109dd",
   "metadata": {},
   "source": [
    "### Generar Respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c19d141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(state: AgentState):\n",
    "    print(\"---AGENTE NODO: Generando Respuesta---\")\n",
    "    user_input = state.get(\"userInput\", \"\")\n",
    "    intent = state.get(\"intent\", \"\")\n",
    "    entities = state.get(\"entities\", {})\n",
    "    catalog_results = state.get(\"catalogQueryResult\", [])\n",
    "    current_call_log = state.get(\"callLog\", [])\n",
    "    context_for_llm = f\"Consulta original (puede ser de voz transcrita): '{user_input}'.\\n\"\n",
    "    context_for_llm += f\"Intención identificada: '{intent}'.\\n\"\n",
    "    if entities: context_for_llm += f\"Entidades: {json.dumps(entities)}.\\n\"\n",
    "    if intent == \"error_nlu_format\" or intent == \"error_nlu_unexpected\":\n",
    "        final_response_text = \"Lo siento, tuve problemas para entender tu solicitud de voz. ¿Podrías intentarlo de nuevo?\"\n",
    "        current_call_log.append(f\"AGENTE_RESPONSE_GEN: Intent='{intent}', Generated_Response='{final_response_text}'\")\n",
    "        return {\"finalResponse\": final_response_text, \"callLog\": current_call_log}\n",
    "    if intent in [\"saludar\", \"despedirse\"] and not catalog_results:\n",
    "        final_response_text = \"¡Hola! Soy tu asistente de compras. ¿En qué puedo ayudarte hoy?\" if intent == \"saludar\" else \"¡Hasta luego!\"\n",
    "        current_call_log.append(f\"AGENTE_RESPONSE_GEN: Intent='{intent}', Generated_Response='{final_response_text}'\")\n",
    "        return {\"finalResponse\": final_response_text, \"callLog\": current_call_log}\n",
    "    system_message_content = \"\"\n",
    "    if not catalog_results:\n",
    "        if intent in [\"buscar_producto\", \"pedir_recomendacion\", \"comparar_productos\"]:\n",
    "            context_for_llm += \"No se encontraron productos que coincidan con tu búsqueda.\\n\"\n",
    "            system_message_content = \"Eres un asistente de compras amigable. Informa al usuario que no se encontraron productos para su búsqueda y sugiere que intente una búsqueda diferente.\"\n",
    "        else:\n",
    "            context_for_llm += \"No se requirió información del catálogo.\\n\"\n",
    "            system_message_content = \"Eres un asistente de compras amigable. Responde concisamente.\"\n",
    "    else:\n",
    "        context_for_llm += \"Productos encontrados:\\n\"\n",
    "        for i, product in enumerate(catalog_results[:3]):\n",
    "            context_for_llm += f\"  P{i+1}: {product.get('nombre', 'N/A')} (Marca: {product.get('marca', 'N/A')}, Precio: ${product.get('precio', 'N/A')})\\n\"\n",
    "            if product.get('descripcion'): context_for_llm += f\"    Desc: {product.get('descripcion')}\\n\"\n",
    "        if len(catalog_results) > 3: context_for_llm += f\"  ... y {len(catalog_results) - 3} más.\\n\"\n",
    "        system_message_content = \"Eres un asistente de compras amigable. Basándote en la consulta y los productos encontrados, genera una respuesta útil.\"\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_message_content),\n",
    "        HumanMessage(content=context_for_llm + \"\\nGenera una respuesta adecuada.\")\n",
    "    ])\n",
    "    try:\n",
    "        formatted_prompt = prompt_template.format_messages()\n",
    "        ai_response = llm.invoke(formatted_prompt)\n",
    "        final_response_text = ai_response.content.strip()\n",
    "        print(f\"Respuesta generada por LLM (Agente): {final_response_text}\")\n",
    "        current_call_log.append(f\"AGENTE_RESPONSE_GEN: Intent='{intent}', Found='{len(catalog_results)}', Generated='{final_response_text[:100]}...'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en generación de respuesta LLM (Agente): {e}\")\n",
    "        current_call_log.append(f\"AGENTE_RESPONSE_GEN_ERROR: {str(e)}\")\n",
    "        final_response_text = \"Lo siento, tengo problemas para generar una respuesta.\"\n",
    "    return {\"finalResponse\": final_response_text, \"callLog\": current_call_log}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9ca92",
   "metadata": {},
   "source": [
    "### Ensamblaje del Grafo LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2c2f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo del Agente LangGraph compilado exitosamente para Nivel 2.\n"
     ]
    }
   ],
   "source": [
    "agent_workflow = StateGraph(AgentState)\n",
    "agent_workflow.add_node(\"nlu_parser_agent\", interpret_user_input)\n",
    "agent_workflow.add_node(\"catalog_tool_agent\", query_product_catalog)\n",
    "agent_workflow.add_node(\"response_generator_agent\", generate_response)\n",
    "agent_workflow.set_entry_point(\"nlu_parser_agent\")\n",
    "agent_workflow.add_edge(\"nlu_parser_agent\", \"catalog_tool_agent\")\n",
    "agent_workflow.add_edge(\"catalog_tool_agent\", \"response_generator_agent\")\n",
    "agent_workflow.add_edge(\"response_generator_agent\", END)\n",
    "\n",
    "try:\n",
    "    agent_app = agent_workflow.compile()\n",
    "    print(\"Grafo del Agente LangGraph compilado exitosamente para Nivel 2.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al compilar el grafo del Agente LangGraph: {e}\")\n",
    "    agent_app = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e80070",
   "metadata": {},
   "source": [
    "### Ejecutar el Agente con el Texto Transcrito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26d69bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EJECUTANDO EL AGENTE CON TEXTO TRANSCRITO ---\n",
      "Entrada para el Agente (texto transcrito): \"buscó un televisor supervisión de 55 pulgadas.\"\n",
      "---AGENTE NODO: Interpretando Entrada del Usuario (con Titan, prompt refinado)---\n",
      "Respuesta cruda del LLM para NLU (Agente-Titan, prompt refinado): {\"intent\": \"buscar_producto\", \"entities\": {\"categoria\": \"televisor\", \"marca\": \"SuperVision\", \"tamaño\": \"55 pulgadas\"}}\n",
      "String JSON potencial extraído (Agente, prompt refinado): {\"intent\": \"buscar_producto\", \"entities\": {\"categoria\": \"televisor\", \"marca\": \"SuperVision\", \"tamaño\": \"55 pulgadas\"}}\n",
      "Intención extraída (Agente, prompt refinado): buscar_producto\n",
      "Entidades extraídas (Agente, prompt refinado): {'categoria': 'televisor', 'marca': 'SuperVision', 'tamaño': '55 pulgadas'}\n",
      "---AGENTE NODO: Consultando Catálogo de Productos---\n",
      "Intentando cargar DB desde: c:\\Users\\Sebastian Diaz G\\OneDrive\\asistente-compras-inteligente\\asistente-compras-inteligente\\data\\products.json\n",
      "Base de datos de productos (Agente) cargada desde 'c:\\Users\\Sebastian Diaz G\\OneDrive\\asistente-compras-inteligente\\asistente-compras-inteligente\\data\\products.json'\n",
      "Consultando catálogo (Agente) con entidades: {'categoria': 'televisor', 'marca': 'SuperVision', 'tamaño': '55 pulgadas'}\n",
      "---AGENTE NODO: Generando Respuesta---\n",
      "Respuesta generada por LLM (Agente): ¡Claro! Encontré un televisor SuperVision OLED 4K 65 pulgadas Pro por $1800.00. Tiene una excelente calidad de imagen y colores vivos. ¿Te interesa?\n",
      "\n",
      "--- RESULTADO FINAL DEL AGENTE (NIVEL 2) ---\n",
      "Respuesta Final del Agente: ¡Claro! Encontré un televisor SuperVision OLED 4K 65 pulgadas Pro por $1800.00. Tiene una excelente calidad de imagen y colores vivos. ¿Te interesa?\n",
      "\n",
      "--- LOG DE LLAMADAS DEL AGENTE (NIVEL 2) ---\n",
      "AGENTE_NLU: Input='buscó un televisor supervisión de 55 pulgadas.', Intent='buscar_producto', Entities='{\"categoria\": \"televisor\", \"marca\": \"SuperVision\", \"tama\\u00f1o\": \"55 pulgadas\"}', LLM_Raw_Output='{\"intent\": \"buscar_producto\", \"entities\": {\"categoria\": \"televisor\", \"marca\": \"SuperVision\", \"tamaño...'\n",
      "AGENTE_CATALOG_QUERY: Entities='{\"categoria\": \"televisor\", \"marca\": \"SuperVision\", \"tama\\u00f1o\": \"55 pulgadas\"}', Found='1 items', ExampleResults='[{\"id\": \"tv004\", \"nombre\": \"Televisor SuperVision OLED 4K 65 pulgadas Pro\"}]'\n",
      "AGENTE_RESPONSE_GEN: Intent='buscar_producto', Found='1', Generated='¡Claro! Encontré un televisor SuperVision OLED 4K 65 pulgadas Pro por $1800.00. Tiene una excelente ...'\n"
     ]
    }
   ],
   "source": [
    "if agent_app and transcribed_text and llm:\n",
    "    print(\"\\n--- EJECUTANDO EL AGENTE CON TEXTO TRANSCRITO ---\")\n",
    "    \n",
    "    agent_initial_input = {\"userInput\": transcribed_text, \"callLog\": []}\n",
    "    print(f\"Entrada para el Agente (texto transcrito): \\\"{transcribed_text}\\\"\")\n",
    "    \n",
    "    try:\n",
    "        agent_final_state = agent_app.invoke(agent_initial_input)\n",
    "\n",
    "        print(\"\\n--- RESULTADO FINAL DEL AGENTE (NIVEL 2) ---\")\n",
    "        final_agent_response = agent_final_state.get('finalResponse', 'No se generó respuesta final del agente.')\n",
    "        print(f\"Respuesta Final del Agente: {final_agent_response}\")\n",
    "        \n",
    "        print(\"\\n--- LOG DE LLAMADAS DEL AGENTE (NIVEL 2) ---\")\n",
    "        if agent_final_state.get('callLog'):\n",
    "            for log_entry in agent_final_state['callLog']:\n",
    "                print(log_entry)\n",
    "        else:\n",
    "            print(\"El log de llamadas del agente está vacío.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la ejecución del agente del Nivel 2: {e}\")\n",
    "\n",
    "elif not transcribed_text:\n",
    "    print(\"No hay texto transcrito para procesar con el agente. Ejecuta la Celda 4 primero.\")\n",
    "elif not agent_app:\n",
    "    print(\"El grafo del agente no se compiló correctamente. Revisa la Celda 10.\")\n",
    "elif not llm:\n",
    "    print(\"El LLM para el agente no está inicializado. Revisa la Celda 5.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
